{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intel_3165_B7.json', 'Intel_3165_A6.json', 'Intel_3165_B1.json', 'Intel_3165_C7.json', 'Intel_3165_A7.json', 'pre_mba_C1.json', 'Intel_3165_A4.json', 'pre_mba_C10.json', 'Intel_3165_B2.json', 'Intel_3165_A8.json', 'Intel_3165_A9.json', 'Intel_3165_C5.json', 'Intel_3165_B3.json', 'pre_mba_C11.json', 'Intel_3165_A5.json', 'Intel_3165_B4.json', 'Intel_3165_C2.json', 'Intel_3165_B8.json', 'Intel_3165_A2.json', 'Intel_3165_A10.json', 'Intel_3165_A3.json', 'Intel_3165_C3.json', 'Intel_3165_B5.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "DIR = '../raw_data/2023_1/'\n",
    "AP_FILE = \"APs.pkl\"\n",
    "RP_FILE = \"RPs.pkl\"\n",
    "META = \"meta.json\"\n",
    "\n",
    "TARGET_APs = []\n",
    "'''\n",
    "list of APs' mac address ['mac0', 'mac1', ... ]\n",
    "'''\n",
    "TARGET_RPs = {}\n",
    "'''\n",
    "dict of RPs {'id1':[rssi_FP1], ... ]\n",
    "id = room#_spot#_orientation\n",
    "rssi_FP are integer list\n",
    "'''\n",
    "os.system(\"rm cluster.json\")\n",
    "\n",
    "scanDir = os.scandir(DIR)\n",
    "jsonFiles = []\n",
    "for f in scanDir:\n",
    "    if f.name.endswith(\".json\"):\n",
    "        jsonFiles.append(f.name)\n",
    "print(jsonFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate AP union\n",
    "index = 0\n",
    "for fn in jsonFiles:\n",
    "    with open(DIR + fn, \"r\") as f:\n",
    "        records = f.readlines()\n",
    "    for row in records:\n",
    "        fp = json.loads(row)[\"fingerprint\"]\n",
    "        if fp == []:\n",
    "            continue\n",
    "        for oneRSSIrecord in fp:\n",
    "            if oneRSSIrecord[1].lower() not in TARGET_APs:\n",
    "                TARGET_APs.append(oneRSSIrecord[1].lower())\n",
    "TARGET_APs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n",
      "2715\n",
      "train set: 272 \t test set: 2443\n"
     ]
    }
   ],
   "source": [
    "randString = lambda : ''.join(random.choices(\"abcdefghijklmnopqrstuvwxyz0123456789\", k=5))\n",
    "# generate FP union\n",
    "for fn in jsonFiles:\n",
    "    with open(DIR + fn, \"r\") as f:\n",
    "        records = f.readlines()\n",
    "    room = fn.split(\".\")[0].split(\"_\")[2]\n",
    "    for row in records:\n",
    "        j = json.loads(row)\n",
    "        id = \".\".join([room, j[\"location\"], j[\"direction\"].lower(), str(j[\"timestamp\"]), randString()])\n",
    "        fp_old = j[\"fingerprint\"]\n",
    "        if fp_old == []:\n",
    "            continue\n",
    "        fp_old_dict = {}\n",
    "        for rssi in fp_old:\n",
    "            fp_old_dict[rssi[1].lower()] = rssi[2]\n",
    "        fp_new = []\n",
    "        for mac in TARGET_APs:\n",
    "            if mac in fp_old_dict.keys():\n",
    "                fp_new.append(fp_old_dict[mac])\n",
    "            else: fp_new.append(None)\n",
    "        TARGET_RPs[id] = fp_new\n",
    "print(len(TARGET_APs))\n",
    "print(len(TARGET_RPs)) \n",
    "\n",
    "# with open(AP_FILE, \"wb\") as apf:\n",
    "#     pickle.dump(TARGET_APs, apf)\n",
    "with open(RP_FILE, \"wb\") as rpf:\n",
    "    pickle.dump(TARGET_RPs, rpf)\n",
    "\n",
    "RP_TRAIN = \"train.pkl\"\n",
    "RP_TEST = \"test.pkl\"\n",
    "train_dict = {}\n",
    "test_dict = {}\n",
    "ratio = 0.9\n",
    "random.seed()\n",
    "test_keys = random.sample(list(TARGET_RPs.keys()), int(ratio * len(TARGET_RPs)))\n",
    "for k in TARGET_RPs.keys():\n",
    "    if k in test_keys:\n",
    "        test_dict[k] = TARGET_RPs[k]\n",
    "    else:\n",
    "        train_dict[k] = TARGET_RPs[k]\n",
    "\n",
    "with open(RP_TRAIN, \"wb\") as rpf:\n",
    "    pickle.dump(train_dict, rpf)\n",
    "with open(RP_TEST, \"wb\") as rpf:\n",
    "    pickle.dump(test_dict, rpf)\n",
    "\n",
    "print(\"train set: {} \\t test set: {}\".format(len(train_dict), len(test_dict)))\n",
    "\n",
    "with open(META, \"w\") as meta:\n",
    "    j = {\n",
    "        \"num_of_ap\" : len(TARGET_APs),\n",
    "        \"num_of_records\" : len(TARGET_RPs),\n",
    "        \"ap_list\" : TARGET_APs,\n",
    "        \"demo\" : {\n",
    "            \"room.pointIndex.orientation.timestamp.random\" : \"list_of_rssi\",\n",
    "            list(TARGET_RPs.keys())[0] : TARGET_RPs[list(TARGET_RPs.keys())[0]]\n",
    "        }\n",
    "    }\n",
    "    meta.write(json.dumps(j, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
